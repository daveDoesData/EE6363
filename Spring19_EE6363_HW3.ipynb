{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBC9XvILl2iR"
   },
   "source": [
    "**EE6363: Advanced Topic - Deep Learning, Spring 2019  |  David Hardage**\n",
    "---\n",
    "## Question I\n",
    "### **RNN Equations**\n",
    "$x_{t}$ is the input for the present \"time\" in a recurrent sequence.\n",
    "\n",
    "$a_{t}$ is the hidden output for that time step in the RNN cell.\n",
    "\n",
    "$a_{t}$ = f($W_{aa}$$a_{t-1}$+$W_{xa}$$x_{t}$+$b_{a}$)\n",
    "\n",
    "### **LSTM Overview**\n",
    "![](https://cdn-images-1.medium.com/max/1800/1*O73nlRM3-bWubvt6W-1YSg.png)\n",
    "LSTMs pass info forward with the aid of their memory gates. These gates are wrapped with a sigmoid so their information is between 0 and 1.\n",
    "#### Forget Gate\n",
    "$f_{t}$ = $\\sigma$($W_{f}$$x_{t}$+$U_{f}$$h_{t-1}$)\n",
    "\n",
    "#### Input Gate\n",
    "$i_{t}$ = $\\sigma$($W_{i}$$x_{t}$+$U_{i}$$h_{t-1}$)\n",
    "\n",
    "#### Output Gate\n",
    "$o_{t}$ = $\\sigma$($W_{o}$$x_{t}$+$U_{o}$$h_{t-1}$)\n",
    "\n",
    "#### Other Functions\n",
    "$C_{t}$ is representative of the new cell state after the input and forget gates.\n",
    "The output gate feeds into the $h_{t}$ =  $o_{t}$*tanh($C_{t})\n",
    "\n",
    "\n",
    "### **RNN's Vanishing Gradient Problem**\n",
    "As the time step in the RNN moves forward, $a_{t}$  becomes $a_{t-1}$ then $a_{t-2}$ then $a_{t-3}$ and so on. The information provided by the first time step is significantly smaller than the last.  The longer the recurrent layers in an RNN the model is more likely to encounter a vanishing gradient because during backpropagation the weights are passed back in time through the hidden states and multiplied by smaller and smaller numbers. Thus, the gradient vanishes. \n",
    "\n",
    "However, this is solved by LSTMs because these cells pass information forward via their built in memory gates, so during back propagation multiplication is not performed over smaller and smaller values.  \n",
    "\n",
    "## Question II\n",
    "![alt text](https://cdn-images-1.medium.com/max/800/0*0ETid8yQzpp-Wiky.png)\n",
    "### One to One\n",
    "Here a single input is classified into a single output. An example of use would be image classification with the task of binary output object detection. \"Is a seagull in this photo?\"\n",
    "\n",
    "### One to Many\n",
    "Here a single input is classified into many categories. Using the image example above, this architecture could detect multiple classes. \"Is there a seagull, seal, and child in this photo?\"\n",
    "\n",
    "### Many to One\n",
    "Here multiple inputs are classified into one output. One could use this architecture to classify sentences into positive or negative sentiment.\n",
    "\n",
    "### Many to Many\n",
    "Multiple inputs generate multiple outputs. This architecture is used in forecasting and language generation task.\n",
    "\n",
    "## Experiment Write Up:\n",
    "We are presented with the task of classifying \"tweets\" as either positive or negative based on the sequence of characters contained in each tweet. A Moderate amount of cleaning was performed on the data to remove htlm and other unnecessary characters. After this processing, the remaining vocabulary size was 6424. Upon performing some exploratory data analysis on the tweets it was discovered 75% of the sequences contained 17 tokens or less, so a token length of 20 was set and the input sequneces padded with 0 to equal to same length. \n",
    "\n",
    "Overall the LSTM performed best, and surprisingly the CNN outperformed RNN. However, I believe the poor performance of the RNN may have been due to padding and set sequence length. Each of the three model architectures below contain as similar of an architecture as possible to enable a fair comparison of performance. Additionally, a Word2Vec embedding was built from the corpus to use as the embedding layer for each model. \n",
    "Comments are included within the model outputs for context. \n",
    "\n",
    "### Word2Vec\n",
    "The word2vec embeddings were built using Gensim. The embedings were built using skip gram and a window of 3 target words in either direction of the known word. Each word outputs 100 dimensions\n",
    "\n",
    "```\n",
    "skpgrm_model = Word2Vec(splitSentences, size=100, window=3, min_count=10, workers=4, sg=1, seed=42)\n",
    "skpgrm_model.save(\"skpgrm_word2vec.model\")\n",
    "skpgrm_model.wv.save_word2vec_format('skpgrm_word2vec.embed')\n",
    "skpgrm_model = gensim.models.KeyedVectors.load_word2vec_format('skpgrm_word2vec.embed')\n",
    "\n",
    "\n",
    "skpgrm_model.get_vector('homework')\n",
    "array([ 0.0133209 , -0.22285783,  0.15449187, -0.26800337,  0.34289762,\n",
    "        0.130753  , -0.20269933,  0.05814106,  0.00448072,  0.10169426,\n",
    "        0.2474094 ,  0.09451383,  0.38079834,  0.18994571, -0.4232437 ,\n",
    "        0.11030207, -0.00634213,  0.04797819, -0.3738323 ,  0.16714379,\n",
    "        0.29844195, -0.24661233, -0.10517423,  0.10951623, -0.23241755,\n",
    "        0.2365318 ,  0.47039396, -0.03204299, -0.00554783, -0.1973574 ,\n",
    "       -0.29617462,  0.29662815, -0.07635267, -0.20394094,  0.27186936,\n",
    "       -0.03534871, -0.21222508,  0.07720903,  0.16229631, -0.18257399,\n",
    "       -0.30284393, -0.05643161, -0.22181787,  0.32325214,  0.0381747 ,\n",
    "       -0.04318884,  0.03069128,  0.11405341, -0.09964969, -0.11250107,\n",
    "       -0.04921242,  0.1064731 , -0.16931188,  0.15360741, -0.31548744,\n",
    "       -0.30717424, -0.13542418,  0.08737126,  0.1196891 , -0.37292108,\n",
    "        0.2103726 , -0.37710935,  0.2584681 ,  0.12948185, -0.2982405 ,\n",
    "        0.13304855, -0.23491664, -0.14256747,  0.14583384, -0.19630934,\n",
    "       -0.16738173, -0.28595325,  0.3356258 ,  0.0494276 , -0.11742572,\n",
    "        0.18208739,  0.18081163,  0.10677474, -0.02403796, -0.31364644,\n",
    "        0.28436786,  0.1565238 , -0.34144282, -0.14650947,  0.09555672,\n",
    "       -0.07998578, -0.01845908, -0.02704127, -0.00394414,  0.1833107 ,\n",
    "       -0.03392621,  0.37270004,  0.06712456, -0.06364433,  0.42783794,\n",
    "        0.19383486,  0.0445508 , -0.2795804 , -0.01937154, -0.06813719],\n",
    "      dtype=float32)\n",
    "```\n",
    "\n",
    "The weight matrix from this embedding was passed into each NN's embeding layer, and this layer was immediately followed with the either a convolutional or reccurent layer. \n",
    "\n",
    "### CNN\n",
    "Building upon our last assigment, we start this analysis by bulding a CNN for twitter sentiment classification.\n",
    "\n",
    "#### Architecture\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "embedding_8 (Embedding)      (None, 20, 100)           642400    \n",
    "_________________________________________________________________\n",
    "conv1d_2 (Conv1D)            (None, 16, 3)             1503      \n",
    "_________________________________________________________________\n",
    "max_pooling1d_2 (MaxPooling1 (None, 3, 3)              0         \n",
    "_________________________________________________________________\n",
    "flatten_2 (Flatten)          (None, 9)                 0         \n",
    "_________________________________________________________________\n",
    "dense_14 (Dense)             (None, 6424)              64240     \n",
    "_________________________________________________________________\n",
    "activation_14 (Activation)   (None, 6424)              0         \n",
    "_________________________________________________________________\n",
    "dropout_4 (Dropout)          (None, 6424)              0         \n",
    "_________________________________________________________________\n",
    "dense_15 (Dense)             (None, 1)                 6425      \n",
    "_________________________________________________________________\n",
    "activation_15 (Activation)   (None, 1)                 0         \n",
    "=================================================================\n",
    "Total params: 714,568\n",
    "Trainable params: 72,168\n",
    "Non-trainable params: 642,400\n",
    "_________________________________________________________________\n",
    "```\n",
    "\n",
    "#### Training Epochs \n",
    "```\n",
    "Train on 72077 samples, validate on 8009 samples\n",
    "Epoch 1/10\n",
    "72077/72077 [==============================] - 2s 29us/step - loss: 0.5961 - acc: 0.6666 - val_loss: 0.5367 - val_acc: 0.7189\n",
    "Epoch 2/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5457 - acc: 0.7179 - val_loss: 0.5344 - val_acc: 0.7254\n",
    "Epoch 3/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5323 - acc: 0.7279 - val_loss: 0.5123 - val_acc: 0.7410\n",
    "Epoch 4/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5242 - acc: 0.7339 - val_loss: 0.5095 - val_acc: 0.7509\n",
    "Epoch 5/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5187 - acc: 0.7383 - val_loss: 0.5141 - val_acc: 0.7399\n",
    "Epoch 6/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5156 - acc: 0.7405 - val_loss: 0.5058 - val_acc: 0.7459\n",
    "Epoch 7/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5125 - acc: 0.7425 - val_loss: 0.5036 - val_acc: 0.7515\n",
    "Epoch 8/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5105 - acc: 0.7439 - val_loss: 0.5062 - val_acc: 0.7479\n",
    "Epoch 9/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5093 - acc: 0.7450 - val_loss: 0.5023 - val_acc: 0.7497\n",
    "Epoch 10/10\n",
    "72077/72077 [==============================] - 1s 17us/step - loss: 0.5073 - acc: 0.7462 - val_loss: 0.5029 - val_acc: 0.7522\n",
    "```\n",
    "Based on the validation accuracy of previous runs,  the CNN would start overfitting around epoch 5. However, the dropout layer looks to account for overfitting in the later epochs.\n",
    "\n",
    "#### Evaluation\n",
    "```\n",
    "100/100 [==============================] - 2s 23ms/step\n",
    "Loss 0.5184418559074402 \n",
    "Accuracy 0.7400391697883606]\n",
    "```\n",
    "\n",
    "\n",
    "### RNN\n",
    "\n",
    "Next, a vanila RNN is implemented to better harness the sequential format of this input data.\n",
    "#### Architecture\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "embedding_7 (Embedding)      (None, 20, 100)           642400    \n",
    "_________________________________________________________________\n",
    "simple_rnn_5 (SimpleRNN)     (None, 100)               20100     \n",
    "_________________________________________________________________\n",
    "dense_12 (Dense)             (None, 6424)              648824    \n",
    "_________________________________________________________________\n",
    "activation_12 (Activation)   (None, 6424)              0         \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 6424)              0         \n",
    "_________________________________________________________________\n",
    "dense_13 (Dense)             (None, 1)                 6425      \n",
    "_________________________________________________________________\n",
    "activation_13 (Activation)   (None, 1)                 0         \n",
    "=================================================================\n",
    "Total params: 1,317,749\n",
    "Trainable params: 675,349\n",
    "Non-trainable params: 642,400\n",
    "_________________________________________________________________\n",
    "```\n",
    "\n",
    "#### Training Epochs \n",
    "```\n",
    "Train on 72077 samples, validate on 8009 samples\n",
    "Epoch 1/10\n",
    "72077/72077 [==============================] - 6s 86us/step - loss: 0.5620 - acc: 0.7055 - val_loss: 0.5235 - val_acc: 0.7329\n",
    "Epoch 2/10\n",
    "72077/72077 [==============================] - 5s 73us/step - loss: 0.5272 - acc: 0.7339 - val_loss: 0.5131 - val_acc: 0.7449\n",
    "Epoch 3/10\n",
    "72077/72077 [==============================] - 5s 73us/step - loss: 0.5097 - acc: 0.7456 - val_loss: 0.5073 - val_acc: 0.7432\n",
    "Epoch 4/10\n",
    "72077/72077 [==============================] - 5s 72us/step - loss: 0.4984 - acc: 0.7532 - val_loss: 0.5040 - val_acc: 0.7520\n",
    "Epoch 5/10\n",
    "72077/72077 [==============================] - 5s 72us/step - loss: 0.4843 - acc: 0.7617 - val_loss: 0.5121 - val_acc: 0.7443\n",
    "Epoch 6/10\n",
    "72077/72077 [==============================] - 5s 72us/step - loss: 0.4701 - acc: 0.7703 - val_loss: 0.5127 - val_acc: 0.7390\n",
    "Epoch 7/10\n",
    "72077/72077 [==============================] - 6s 84us/step - loss: 0.4508 - acc: 0.7832 - val_loss: 0.5334 - val_acc: 0.7313\n",
    "Epoch 8/10\n",
    "72077/72077 [==============================] - 5s 73us/step - loss: 0.4318 - acc: 0.7956 - val_loss: 0.5345 - val_acc: 0.7463\n",
    "Epoch 9/10\n",
    "72077/72077 [==============================] - 5s 73us/step - loss: 0.4101 - acc: 0.8089 - val_loss: 0.5497 - val_acc: 0.7258\n",
    "Epoch 10/10\n",
    "72077/72077 [==============================] - 5s 72us/step - loss: 0.3882 - acc: 0.8219 - val_loss: 0.5804 - val_acc: 0.7331\n",
    "```\n",
    "Here the dropout layer stabalizes overfitting in the later epochs.\n",
    "\n",
    "#### Evaluation\n",
    "```\n",
    "100/100 [==============================] - 5s 52ms/step\n",
    "loss 0.604823112487793 \n",
    "accuracy 0.7234587669372559\n",
    "```\n",
    "The RNN does not perform as well as the CNN. This is likely due to the padding of the data. Since the padding occurs at the end of the sequence, the information from the earlier occurring non-padding terms is diminished by the time we get to the output at time step 20.\n",
    "\n",
    "### LSTM\n",
    "\n",
    "Last, a LSTM is implemented to better help with this information loss and pass valuable signal from earlier occurring features forward.\n",
    "#### Architecture\n",
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "embedding_9 (Embedding)      (None, 20, 100)           642400    \n",
    "_________________________________________________________________\n",
    "lstm_2 (LSTM)                (None, 100)               80400     \n",
    "_________________________________________________________________\n",
    "dense_16 (Dense)             (None, 6424)              648824    \n",
    "_________________________________________________________________\n",
    "activation_16 (Activation)   (None, 6424)              0         \n",
    "_________________________________________________________________\n",
    "dropout_5 (Dropout)          (None, 6424)              0         \n",
    "_________________________________________________________________\n",
    "dense_17 (Dense)             (None, 1)                 6425      \n",
    "_________________________________________________________________\n",
    "activation_17 (Activation)   (None, 1)                 0         \n",
    "=================================================================\n",
    "Total params: 1,378,049\n",
    "Trainable params: 735,649\n",
    "Non-trainable params: 642,400\n",
    "_________________________________________________________________\n",
    "```\n",
    "\n",
    "#### Training Epochs \n",
    "```\n",
    "Epoch 1/10\n",
    "72077/72077 [==============================] - 15s 208us/step - loss: 0.5458 - acc: 0.7177 - val_loss: 0.5067 - val_acc: 0.7449\n",
    "Epoch 2/10\n",
    "72077/72077 [==============================] - 13s 183us/step - loss: 0.5148 - acc: 0.7400 - val_loss: 0.4941 - val_acc: 0.7515\n",
    "Epoch 3/10\n",
    "72077/72077 [==============================] - 12s 173us/step - loss: 0.5032 - acc: 0.7492 - val_loss: 0.4852 - val_acc: 0.7581\n",
    "Epoch 4/10\n",
    "72077/72077 [==============================] - 13s 183us/step - loss: 0.4933 - acc: 0.7562 - val_loss: 0.4841 - val_acc: 0.7604\n",
    "Epoch 5/10\n",
    "72077/72077 [==============================] - 12s 173us/step - loss: 0.4853 - acc: 0.7609 - val_loss: 0.4779 - val_acc: 0.7679\n",
    "Epoch 6/10\n",
    "72077/72077 [==============================] - 12s 172us/step - loss: 0.4772 - acc: 0.7653 - val_loss: 0.4763 - val_acc: 0.7705\n",
    "Epoch 7/10\n",
    "72077/72077 [==============================] - 12s 173us/step - loss: 0.4707 - acc: 0.7708 - val_loss: 0.4850 - val_acc: 0.7621\n",
    "Epoch 8/10\n",
    "72077/72077 [==============================] - 14s 191us/step - loss: 0.4636 - acc: 0.7748 - val_loss: 0.4790 - val_acc: 0.7669\n",
    "Epoch 9/10\n",
    "72077/72077 [==============================] - 12s 172us/step - loss: 0.4558 - acc: 0.7805 - val_loss: 0.4777 - val_acc: 0.7670\n",
    "Epoch 10/10\n",
    "72077/72077 [==============================] - 12s 173us/step - loss: 0.4460 - acc: 0.7854 - val_loss: 0.4735 - val_acc: 0.7665\n",
    "```\n",
    "#### Evaluation\n",
    "```\n",
    "100/100 [==============================] - 13s 127ms/step\n",
    "Loss 0.48326265811920166\n",
    "Accuracy 0.7662161588668823\n",
    "```\n",
    "As expected, the LSTM outperforms both CNN and RNN. This is because the LSTM is able to learn from the sequence's meaning and pass forward information from earlier vectors in the sequence and use this information in it's prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDSjtSzwrHvX"
   },
   "source": [
    "## Sources:\n",
    "Deep Learning, Goodfellow-et-al-2016, http://www.deeplearningbook.org/\n",
    "\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UW4xRZYvu3A0"
   },
   "source": [
    "## Appendix: Experiment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uxRZNMwEVCr"
   },
   "source": [
    "### Data Import, Cleaning and W2V Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "8qTLXSJX06-n",
    "outputId": "1ceae4c2-e3c3-4f2b-d781-813d4e73b9fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-92163f74-d8a8-4d0f-beca-062c9211aad9\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-92163f74-d8a8-4d0f-beca-062c9211aad9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train.csv to train.csv\n",
      "User uploaded file \"train.csv\" with length 8664015 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aIP1EZfavP5l",
    "outputId": "86e35e0e-7d09-4a22-bd71-1329db8d561e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "RRsnc36V5-IL",
    "outputId": "fa0d2132-2e67-4da4-ea89-18000319d910"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = pd.read_csv('train.csv', encoding='latin-1')\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TsB9kvEKh3C"
   },
   "outputs": [],
   "source": [
    "sentences = traindf['SentimentText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlauT4MpKcdq"
   },
   "outputs": [],
   "source": [
    "#remove @ mentions \n",
    "sentences = [re.sub(r'@[A-Za-z0-9]+','',str(sentence)) for sentence in sentences]\n",
    "#remove urls\n",
    "sentences = [re.sub(r'https?://[A-Za-z0-9./]+','',str(sentence)) for sentence in sentences]\n",
    "#remove non-letters  \n",
    "sentences = [re.sub(r'[^a-zA-Z]',' ',str(sentence)) for sentence in sentences]\n",
    "#lower\n",
    "sentences = [sentence.lower() for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "aOWIyrjTNUws",
    "outputId": "07b4f723-83f0-487e-930b-7af3a71946f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>cleanSentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>is so sad for my apl frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>i missed the new moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg its already       o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>omgaga  im sooo  im gunna cry  i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>i think mi bf is cheating on me      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText  \\\n",
       "0       1          0                       is so sad for my APL frie...   \n",
       "1       2          0                     I missed the New Moon trail...   \n",
       "2       3          1                            omg its already 7:30 :O   \n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4       5          0           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "                                  cleanSentimentText  \n",
       "0                       is so sad for my apl frie...  \n",
       "1                     i missed the new moon trail...  \n",
       "2                            omg its already       o  \n",
       "3               omgaga  im sooo  im gunna cry  i ...  \n",
       "4           i think mi bf is cheating on me      ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['cleanSentimentText'] = sentences\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "h9vgtZhuQ6k4",
    "outputId": "43e0d764-e2b2-45c1-d880-3460a79caa09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     is so sad for my apl friend             \n",
      "['is', 'so', 'sad', 'for', 'my', 'apl', 'friend']\n"
     ]
    }
   ],
   "source": [
    "line = traindf['cleanSentimentText'][0]\n",
    "print(line)\n",
    "split = line.split()\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2OCLUQI561Vv"
   },
   "source": [
    "### Create Word 2 Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkrW29wF9f5S"
   },
   "outputs": [],
   "source": [
    "# define training data\n",
    "sentences = traindf['cleanSentimentText']\n",
    "splitSentences = [sentence.split() for sentence in sentences]\n",
    "traindf['splitSentences'] = splitSentences\n",
    "# train models\n",
    "skpgrm_model = Word2Vec(splitSentences, size=100, window=3, min_count=10, workers=4, sg=1, seed=42)\n",
    "skpgrm_model.save(\"skpgrm_word2vec.model\")\n",
    "\n",
    "\n",
    "cbow_model = Word2Vec(splitSentences, size=100, window=3, min_count=10, workers=4, sg=0, seed=42)\n",
    "cbow_model.save(\"cbow_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aob9L2kvkBc7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sII65hPFUC-v"
   },
   "outputs": [],
   "source": [
    "skpgrm_model.wv.save_word2vec_format('skpgrm_word2vec.embed')\n",
    "cbow_model.wv.save_word2vec_format('cbow_word2vec.embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghkcXPijUDB7"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "skpgrm_model = gensim.models.KeyedVectors.load_word2vec_format('skpgrm_word2vec.embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQSCwCHia-yR"
   },
   "outputs": [],
   "source": [
    "cbow_model = gensim.models.KeyedVectors.load_word2vec_format('cbow_word2vec.embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dyy2CsIxnEhO",
    "outputId": "4c92de06-0cfd-4240-b2ec-3aa6fa61e0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3591\n"
     ]
    }
   ],
   "source": [
    "word = \"pad\"  # for any word in model\n",
    "i = skpgrm_model.vocab[word].index\n",
    "skpgrm_model.index2word[i] \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iHsWAQqarMIQ",
    "outputId": "922fbd10-2e84-44f5-cc53-0f821e034285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "word = skpgrm_model.index2word[i] \n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "7eio5cP9dRqR",
    "outputId": "ba59ad03-c96f-4342-f0d6-45bc2f3bf851"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0133209 , -0.22285783,  0.15449187, -0.26800337,  0.34289762,\n",
       "        0.130753  , -0.20269933,  0.05814106,  0.00448072,  0.10169426,\n",
       "        0.2474094 ,  0.09451383,  0.38079834,  0.18994571, -0.4232437 ,\n",
       "        0.11030207, -0.00634213,  0.04797819, -0.3738323 ,  0.16714379,\n",
       "        0.29844195, -0.24661233, -0.10517423,  0.10951623, -0.23241755,\n",
       "        0.2365318 ,  0.47039396, -0.03204299, -0.00554783, -0.1973574 ,\n",
       "       -0.29617462,  0.29662815, -0.07635267, -0.20394094,  0.27186936,\n",
       "       -0.03534871, -0.21222508,  0.07720903,  0.16229631, -0.18257399,\n",
       "       -0.30284393, -0.05643161, -0.22181787,  0.32325214,  0.0381747 ,\n",
       "       -0.04318884,  0.03069128,  0.11405341, -0.09964969, -0.11250107,\n",
       "       -0.04921242,  0.1064731 , -0.16931188,  0.15360741, -0.31548744,\n",
       "       -0.30717424, -0.13542418,  0.08737126,  0.1196891 , -0.37292108,\n",
       "        0.2103726 , -0.37710935,  0.2584681 ,  0.12948185, -0.2982405 ,\n",
       "        0.13304855, -0.23491664, -0.14256747,  0.14583384, -0.19630934,\n",
       "       -0.16738173, -0.28595325,  0.3356258 ,  0.0494276 , -0.11742572,\n",
       "        0.18208739,  0.18081163,  0.10677474, -0.02403796, -0.31364644,\n",
       "        0.28436786,  0.1565238 , -0.34144282, -0.14650947,  0.09555672,\n",
       "       -0.07998578, -0.01845908, -0.02704127, -0.00394414,  0.1833107 ,\n",
       "       -0.03392621,  0.37270004,  0.06712456, -0.06364433,  0.42783794,\n",
       "        0.19383486,  0.0445508 , -0.2795804 , -0.01937154, -0.06813719],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skpgrm_model.get_vector('homework')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urXyKRmBnFC9"
   },
   "outputs": [],
   "source": [
    "sentenceIndexs = []\n",
    "for line in traindf['splitSentences']:\n",
    "  index = []\n",
    "  for word in line:\n",
    "    try:\n",
    "      i = skpgrm_model.vocab[word].index\n",
    "      index.append(i)\n",
    "    except Exception:\n",
    "      pass \n",
    "  sentenceIndexs.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9As33vAEFNyM"
   },
   "outputs": [],
   "source": [
    "traindf['sentenceIndex'] = sentenceIndexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gebCEKHcaZkY"
   },
   "outputs": [],
   "source": [
    "traindf_features_list = traindf['sentenceIndex'].values\n",
    "traindf_features_np = np.array([np.array(line) for line in traindf_features_list])\n",
    "max_len = np.max([len(a) for a in traindf_features_np])\n",
    "traindf_features_np = [np.pad(a, (0, max_len - len(a)), 'constant', constant_values=0) for a in traindf_features_np]\n",
    "features = []\n",
    "for line in traindf_features_np:\n",
    "  features.append(line[:20]) #trim the padded list items to the first 20 elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fkcT-xym6mgA",
    "outputId": "87b72670-01c1-48dc-c332-ecc22e098236"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>cleanSentimentText</th>\n",
       "      <th>splitSentences</th>\n",
       "      <th>sentenceIndex</th>\n",
       "      <th>features</th>\n",
       "      <th>featuresLength</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>is so sad for my apl frie...</td>\n",
       "      <td>[is, so, sad, for, my, apl, friend]</td>\n",
       "      <td>[12, 18, 121, 10, 7, 254]</td>\n",
       "      <td>[12, 18, 121, 10, 7, 254, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>i missed the new moon trail...</td>\n",
       "      <td>[i, missed, the, new, moon, trailer]</td>\n",
       "      <td>[0, 239, 2, 106, 1032, 1638]</td>\n",
       "      <td>[0, 239, 2, 106, 1032, 1638, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg its already       o</td>\n",
       "      <td>[omg, its, already, o]</td>\n",
       "      <td>[235, 80, 199, 212]</td>\n",
       "      <td>[235, 80, 199, 212, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>omgaga  im sooo  im gunna cry  i ...</td>\n",
       "      <td>[omgaga, im, sooo, im, gunna, cry, i, ve, been...</td>\n",
       "      <td>[73, 522, 73, 1743, 548, 0, 100, 92, 34, 42, 2...</td>\n",
       "      <td>[73, 522, 73, 1743, 548, 0, 100, 92, 34, 42, 2...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>i think mi bf is cheating on me      ...</td>\n",
       "      <td>[i, think, mi, bf, is, cheating, on, me, t, t]</td>\n",
       "      <td>[0, 71, 2118, 1400, 12, 4066, 17, 14, 11, 11]</td>\n",
       "      <td>[0, 71, 2118, 1400, 12, 4066, 17, 14, 11, 11, ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText  \\\n",
       "0       1          0                       is so sad for my APL frie...   \n",
       "1       2          0                     I missed the New Moon trail...   \n",
       "2       3          1                            omg its already 7:30 :O   \n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "4       5          0           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "                                  cleanSentimentText  \\\n",
       "0                       is so sad for my apl frie...   \n",
       "1                     i missed the new moon trail...   \n",
       "2                            omg its already       o   \n",
       "3               omgaga  im sooo  im gunna cry  i ...   \n",
       "4           i think mi bf is cheating on me      ...   \n",
       "\n",
       "                                      splitSentences  \\\n",
       "0                [is, so, sad, for, my, apl, friend]   \n",
       "1               [i, missed, the, new, moon, trailer]   \n",
       "2                             [omg, its, already, o]   \n",
       "3  [omgaga, im, sooo, im, gunna, cry, i, ve, been...   \n",
       "4     [i, think, mi, bf, is, cheating, on, me, t, t]   \n",
       "\n",
       "                                       sentenceIndex  \\\n",
       "0                          [12, 18, 121, 10, 7, 254]   \n",
       "1                       [0, 239, 2, 106, 1032, 1638]   \n",
       "2                                [235, 80, 199, 212]   \n",
       "3  [73, 522, 73, 1743, 548, 0, 100, 92, 34, 42, 2...   \n",
       "4      [0, 71, 2118, 1400, 12, 4066, 17, 14, 11, 11]   \n",
       "\n",
       "                                            features  featuresLength  label  \n",
       "0  [12, 18, 121, 10, 7, 254, 0, 0, 0, 0, 0, 0, 0,...              20      0  \n",
       "1  [0, 239, 2, 106, 1032, 1638, 0, 0, 0, 0, 0, 0,...              20      0  \n",
       "2  [235, 80, 199, 212, 0, 0, 0, 0, 0, 0, 0, 0, 0,...              20      1  \n",
       "3  [73, 522, 73, 1743, 548, 0, 100, 92, 34, 42, 2...              20      0  \n",
       "4  [0, 71, 2118, 1400, 12, 4066, 17, 14, 11, 11, ...              20      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['features']=features\n",
    "featuresLength = []\n",
    "for line in traindf['features']:\n",
    "  length = len(line)\n",
    "  featuresLength.append(length)\n",
    " \n",
    "traindf['featuresLength']=featuresLength\n",
    "traindf['label']=traindf['Sentiment']\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "WMdeUcVP7Zum",
    "outputId": "5d0220c9-4095-4153-ebeb-2d8bc525b09d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[12, 18, 121, 10, 7, 254, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 239, 2, 106, 1032, 1638, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[235, 80, 199, 212, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[73, 522, 73, 1743, 548, 0, 100, 92, 34, 42, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 71, 2118, 1400, 12, 4066, 17, 14, 11, 11, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  [12, 18, 121, 10, 7, 254, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "1  [0, 239, 2, 106, 1032, 1638, 0, 0, 0, 0, 0, 0,...      0\n",
       "2  [235, 80, 199, 212, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "3  [73, 522, 73, 1743, 548, 0, 100, 92, 34, 42, 2...      0\n",
       "4  [0, 71, 2118, 1400, 12, 4066, 17, 14, 11, 11, ...      0"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldf = traindf[['features','label']]\n",
    "modeldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Q1mc1vVjQnf"
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(traindf)) < 0.8\n",
    "train = modeldf[msk]\n",
    "dev = modeldf[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qus_OaK5NeUi"
   },
   "outputs": [],
   "source": [
    "trainFeatList = train['features'].values\n",
    "train_x=np.array([np.array(y) for y in trainFeatList])\n",
    "train_y=np.array(train['label'])\n",
    "\n",
    "devFeatList = dev['features'].values\n",
    "dev_x=np.array([np.array(y) for y in devFeatList])\n",
    "dev_y=np.array(dev['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Y7fV74potQ88",
    "outputId": "f032cfeb-d6db-49f4-a8cb-7937b011ba3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.200e+01 1.800e+01 1.210e+02 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [2.350e+02 8.000e+01 1.990e+02 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [7.300e+01 5.220e+02 7.300e+01 ... 5.562e+03 3.160e+02 1.700e+01]\n",
      " ...\n",
      " [3.700e+01 3.350e+02 1.345e+03 ... 1.020e+02 1.720e+02 2.000e+00]\n",
      " [1.050e+02 1.050e+02 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [7.200e+01 1.050e+02 1.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-v_v_RNG2Jr"
   },
   "source": [
    "### Keras Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDbsoJ2dG6Ep"
   },
   "outputs": [],
   "source": [
    "vocab_size = 6424\n",
    "seq_size = 20\n",
    "emdedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xA0PEkuGJ9PY"
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QF4ZLYVhxVee"
   },
   "outputs": [],
   "source": [
    "CNNet = Sequential()\n",
    "CNNet.add(Embedding(vocab_size,\n",
    "                    emdedding_size,\n",
    "                    weights=[skpgrm_model.vectors],\n",
    "                    input_length = 20,\n",
    "                    #mask_zero=True,\n",
    "                    trainable=False))\n",
    "CNNet.add(Conv1D(filters=3,\n",
    "                         kernel_size=5,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1))\n",
    "CNNet.add(MaxPooling1D(pool_size=5))\n",
    "CNNet.add(Flatten())\n",
    "CNNet.add(Dense(units=vocab_size))\n",
    "CNNet.add(Activation('relu'))\n",
    "CNNet.add(Dropout(rate=0.25, seed=42))\n",
    "CNNet.add(Dense(units=1))\n",
    "CNNet.add(Activation('sigmoid'))\n",
    "CNNet.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "g7foHzI8zYQ7",
    "outputId": "b06bb7b4-7562-475f-dfdb-b29c1eb4380c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72077 samples, validate on 8009 samples\n",
      "Epoch 1/10\n",
      "72077/72077 [==============================] - 2s 29us/step - loss: 0.5961 - acc: 0.6666 - val_loss: 0.5367 - val_acc: 0.7189\n",
      "Epoch 2/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5457 - acc: 0.7179 - val_loss: 0.5344 - val_acc: 0.7254\n",
      "Epoch 3/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5323 - acc: 0.7279 - val_loss: 0.5123 - val_acc: 0.7410\n",
      "Epoch 4/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5242 - acc: 0.7339 - val_loss: 0.5095 - val_acc: 0.7509\n",
      "Epoch 5/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5187 - acc: 0.7383 - val_loss: 0.5141 - val_acc: 0.7399\n",
      "Epoch 6/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5156 - acc: 0.7405 - val_loss: 0.5058 - val_acc: 0.7459\n",
      "Epoch 7/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5125 - acc: 0.7425 - val_loss: 0.5036 - val_acc: 0.7515\n",
      "Epoch 8/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5105 - acc: 0.7439 - val_loss: 0.5062 - val_acc: 0.7479\n",
      "Epoch 9/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5093 - acc: 0.7450 - val_loss: 0.5023 - val_acc: 0.7497\n",
      "Epoch 10/10\n",
      "72077/72077 [==============================] - 1s 17us/step - loss: 0.5073 - acc: 0.7462 - val_loss: 0.5029 - val_acc: 0.7522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d38183a90>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNet.reset_states()\n",
    "CNNet.fit(train_x, train_y, \n",
    "  batch_size=250,\n",
    "  epochs=10,\n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "lwFkKz-Qv1mh",
    "outputId": "122b8462-c9a7-4cd4-d3dc-af88bc402912"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(units=100, input_shape=(None, 20))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "RNNet = Sequential()\n",
    "RNNet.add(Embedding(vocab_size,\n",
    "                    emdedding_size,\n",
    "                    weights=[skpgrm_model.vectors],\n",
    "                    input_length = 20,\n",
    "                    mask_zero=True,\n",
    "                    trainable=False))\n",
    "RNNet.add(SimpleRNN(units=emdedding_size, input_dim=20))\n",
    "RNNet.add(Dense(units=vocab_size))\n",
    "RNNet.add(Activation('relu'))\n",
    "RNNet.add(Dropout(rate=0.25, seed=42))\n",
    "RNNet.add(Dense(units=1))\n",
    "RNNet.add(Activation('sigmoid'))\n",
    "RNNet.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "mEcqWBX-wm_F",
    "outputId": "c260fe59-510b-4a3f-ca94-4a5a308abe8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72077 samples, validate on 8009 samples\n",
      "Epoch 1/10\n",
      "72077/72077 [==============================] - 6s 86us/step - loss: 0.5620 - acc: 0.7055 - val_loss: 0.5235 - val_acc: 0.7329\n",
      "Epoch 2/10\n",
      "72077/72077 [==============================] - 5s 73us/step - loss: 0.5272 - acc: 0.7339 - val_loss: 0.5131 - val_acc: 0.7449\n",
      "Epoch 3/10\n",
      "72077/72077 [==============================] - 5s 73us/step - loss: 0.5097 - acc: 0.7456 - val_loss: 0.5073 - val_acc: 0.7432\n",
      "Epoch 4/10\n",
      "72077/72077 [==============================] - 5s 72us/step - loss: 0.4984 - acc: 0.7532 - val_loss: 0.5040 - val_acc: 0.7520\n",
      "Epoch 5/10\n",
      "72077/72077 [==============================] - 5s 72us/step - loss: 0.4843 - acc: 0.7617 - val_loss: 0.5121 - val_acc: 0.7443\n",
      "Epoch 6/10\n",
      "72077/72077 [==============================] - 5s 72us/step - loss: 0.4701 - acc: 0.7703 - val_loss: 0.5127 - val_acc: 0.7390\n",
      "Epoch 7/10\n",
      "72077/72077 [==============================] - 6s 84us/step - loss: 0.4508 - acc: 0.7832 - val_loss: 0.5334 - val_acc: 0.7313\n",
      "Epoch 8/10\n",
      "72077/72077 [==============================] - 5s 73us/step - loss: 0.4318 - acc: 0.7956 - val_loss: 0.5345 - val_acc: 0.7463\n",
      "Epoch 9/10\n",
      "72077/72077 [==============================] - 5s 73us/step - loss: 0.4101 - acc: 0.8089 - val_loss: 0.5497 - val_acc: 0.7258\n",
      "Epoch 10/10\n",
      "72077/72077 [==============================] - 5s 72us/step - loss: 0.3882 - acc: 0.8219 - val_loss: 0.5804 - val_acc: 0.7331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d38964208>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNet.reset_states()\n",
    "RNNet.fit(train_x, train_y, \n",
    "  batch_size=250,\n",
    "  epochs=10,\n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mKOKw4f9KSMF",
    "outputId": "18ae580d-9717-4915-e7a9-0fc4c5555033"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=100, input_shape=(None, 20))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "LSTMNet = Sequential()\n",
    "LSTMNet.add(Embedding(vocab_size,\n",
    "                    emdedding_size,\n",
    "                    weights=[skpgrm_model.vectors],\n",
    "                    input_length = 20,\n",
    "                    mask_zero=True,\n",
    "                    trainable=False))\n",
    "LSTMNet.add(LSTM(units=emdedding_size, input_dim=20))\n",
    "LSTMNet.add(Dense(units=vocab_size))\n",
    "LSTMNet.add(Activation('relu'))\n",
    "LSTMNet.add(Dropout(rate=0.25, seed=42))\n",
    "LSTMNet.add(Dense(units=1))\n",
    "LSTMNet.add(Activation('sigmoid'))\n",
    "LSTMNet.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "dyFniCgkM0m1",
    "outputId": "8497d76d-8160-4322-fe11-0b4d279a7e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72077 samples, validate on 8009 samples\n",
      "Epoch 1/10\n",
      "72077/72077 [==============================] - 15s 208us/step - loss: 0.5458 - acc: 0.7177 - val_loss: 0.5067 - val_acc: 0.7449\n",
      "Epoch 2/10\n",
      "72077/72077 [==============================] - 13s 183us/step - loss: 0.5148 - acc: 0.7400 - val_loss: 0.4941 - val_acc: 0.7515\n",
      "Epoch 3/10\n",
      "72077/72077 [==============================] - 12s 173us/step - loss: 0.5032 - acc: 0.7492 - val_loss: 0.4852 - val_acc: 0.7581\n",
      "Epoch 4/10\n",
      "72077/72077 [==============================] - 13s 183us/step - loss: 0.4933 - acc: 0.7562 - val_loss: 0.4841 - val_acc: 0.7604\n",
      "Epoch 5/10\n",
      "72077/72077 [==============================] - 12s 173us/step - loss: 0.4853 - acc: 0.7609 - val_loss: 0.4779 - val_acc: 0.7679\n",
      "Epoch 6/10\n",
      "72077/72077 [==============================] - 12s 172us/step - loss: 0.4772 - acc: 0.7653 - val_loss: 0.4763 - val_acc: 0.7705\n",
      "Epoch 7/10\n",
      "72077/72077 [==============================] - 12s 173us/step - loss: 0.4707 - acc: 0.7708 - val_loss: 0.4850 - val_acc: 0.7621\n",
      "Epoch 8/10\n",
      "72077/72077 [==============================] - 14s 191us/step - loss: 0.4636 - acc: 0.7748 - val_loss: 0.4790 - val_acc: 0.7669\n",
      "Epoch 9/10\n",
      "72077/72077 [==============================] - 12s 172us/step - loss: 0.4558 - acc: 0.7805 - val_loss: 0.4777 - val_acc: 0.7670\n",
      "Epoch 10/10\n",
      "72077/72077 [==============================] - 12s 173us/step - loss: 0.4460 - acc: 0.7854 - val_loss: 0.4735 - val_acc: 0.7665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d381f2550>"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTMNet.reset_states()\n",
    "LSTMNet.fit(train_x, train_y, \n",
    "  batch_size=250,\n",
    "  epochs=10,\n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c6yPVijrK63k",
    "outputId": "787963b5-ca8a-4ae7-af4b-6ce335c81938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5184418559074402, 0.7400391697883606]"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNet.evaluate(dev_x, dev_y,  \n",
    "                   verbose=1, \n",
    "                   steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "nL1iVoXzLdDX",
    "outputId": "06dd3a67-b475-4ad1-a2ba-e444fb09325b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 20, 100)           642400    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 3)             1503      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3, 3)              0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6424)              64240     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 6424)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6424)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 6425      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 714,568\n",
      "Trainable params: 72,168\n",
      "Non-trainable params: 642,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m2nuPzHRK67W",
    "outputId": "6380dc5d-64e2-421b-87ad-f59cf9ce46a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 5s 52ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.604823112487793, 0.7234587669372559]"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNet.evaluate(dev_x, dev_y,  \n",
    "                   verbose=1, \n",
    "                   steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "3ZYObgcjLf4t",
    "outputId": "11ca8c87-5f9a-4ca3-ca52-bb764f91634e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 20, 100)           642400    \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6424)              648824    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 6424)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6424)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 6425      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,317,749\n",
      "Trainable params: 675,349\n",
      "Non-trainable params: 642,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LghrlAnGFuP9",
    "outputId": "51d5cc92-5daa-4556-bd70-de71b2b8e045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 13s 127ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48326265811920166, 0.7662161588668823]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTMNet.evaluate(dev_x, dev_y,  \n",
    "                   verbose=1, \n",
    "                   steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "-sSzz2H4Lj4X",
    "outputId": "2ca5c95f-bf25-43eb-b0bc-9babbd80d042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 20, 100)           642400    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6424)              648824    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 6424)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6424)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 6425      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,378,049\n",
      "Trainable params: 735,649\n",
      "Non-trainable params: 642,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTMNet.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Spring19_EE6363_HW3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
